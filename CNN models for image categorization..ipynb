{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "edrrZbmd29Vc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2via-143SmJ",
        "outputId": "83022f64-9fee-40ec-8c8b-59bc460a7a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oRWmVVac-1Uz"
      },
      "outputs": [],
      "source": [
        "input_shape = (32, 32, 3) # CIFAR-10 images are 32x32 with 3 color channels\n",
        "num_classes = 10 # There are 10 classification (car,truck,bike...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "wQjxdqGYLGwe",
        "outputId": "3a7778b7-afb9-45f0-ea1f-dcfabc4be0bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" # CNN Layer 1\\n    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\\n    model.add(MaxPooling2D((2, 2)))\\n\\n    # CNN Layer 2\\n    model.add(Conv2D(64, (3, 3), activation='relu'))\\n    model.add(MaxPooling2D((2, 2)))\\n\\n    # CNN Layer 3\\n    model.add(Conv2D(128, (3, 3), activation='relu'))\\n    model.add(MaxPooling2D((2, 2)))\\n\\n    # Flattening layer\\n    model.add(Flatten())\\n\\n    # Fully connected layer\\n    model.add(Dense(128, activation='relu'))\\n\\n    # Output layer\\n    model.add(Dense(num_classes, activation='softmax'))\\n\\n    return model\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" # CNN Layer 1\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # CNN Layer 2\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # CNN Layer 3\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Flattening layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D9mCfeQk_fEC"
      },
      "outputs": [],
      "source": [
        "def build_cnn(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add Convolutional layers with hyperparameter tuning\n",
        "    for i in range(hp.Int('conv_layers', 1, 3)):  # Number of convolutional layers\n",
        "        model.add(Conv2D(\n",
        "            hp.Choice(f'filters_{i}', values=[32, 64, 128]),\n",
        "            (3, 3),\n",
        "            activation='relu',\n",
        "            input_shape=input_shape if i == 0 else None\n",
        "        ))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Flattening layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layer with hyperparameter tuning\n",
        "    model.add(Dense(\n",
        "        hp.Int('dense_units', min_value=64, max_value=256, step=64),\n",
        "        activation='relu'\n",
        "    ))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    compile_model(model, hp)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oOTjRkrYA-L7"
      },
      "outputs": [],
      "source": [
        "def compile_model(model, hp):\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', values=['adam', 'sgd']),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FL0b6R4zBqpL"
      },
      "outputs": [],
      "source": [
        "#epochs = 1000\n",
        "#batch_size = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x3eGwRDkBWvS"
      },
      "outputs": [],
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test):\n",
        "\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=10,\n",
        "        batch_size=12,\n",
        "        validation_data=(x_test, y_test),\n",
        "\n",
        "    )\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "htnJfCBrB3ZD"
      },
      "outputs": [],
      "source": [
        "def model_summary(model):\n",
        "  model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xUMEqpo9B_Wi"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model,x_test,y_test):\n",
        "  loss,acc = model.evaluate(x_test,y_test)\n",
        "  print('TESTING ACCURACY',acc)\n",
        "  print('TESTING LOSS',loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3t_Ehm4qFKAh"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VseOJjEPMRWp"
      },
      "outputs": [],
      "source": [
        "def hyperparameter_tuning(x_train, y_train, x_test, y_test):\n",
        "    # Define the Tuner\n",
        "    tuner = kt.Hyperband(\n",
        "        build_cnn,\n",
        "        objective='val_accuracy',\n",
        "        max_epochs=10,\n",
        "        hyperband_iterations=2,\n",
        "        directory='my_dir',\n",
        "        project_name='cifar10_tuning'\n",
        "    )\n",
        "    tuner.search(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "  # Retrieve the best model\n",
        "    best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "  # Evaluate the best model\n",
        "    loss, acc = best_model.evaluate(x_test, y_test, verbose=2)\n",
        "    print('Best model accuracy:', acc)\n",
        "    print('Best model loss:', loss)\n",
        "\n",
        "    # Plot the training and validation accuracy of the best model\n",
        "    history = tuner.get_best_hyperparameters()[0].get('history')\n",
        "    plot_accuracy(history)\n",
        "\n",
        "    # Summary of the best model\n",
        "    best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "N3afWh-iCb43",
        "outputId": "8542050f-d730-4d4f-e417-5abe78cdce4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 60 Complete [00h 01m 09s]\n",
            "val_accuracy: 0.6604999899864197\n",
            "\n",
            "Best val_accuracy So Far: 0.7199000120162964\n",
            "Total elapsed time: 00h 33m 46s\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7199 - loss: 1.1083\n",
            "Best model accuracy: 0.7199000120162964\n",
            "Best model loss: 1.1083009243011475\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'history does not exist.'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ece23991ef54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-ec3c830268fd>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Plot the training and validation accuracy of the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hyperparameters/hyperparameters.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name} is currently inactive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name} does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'history does not exist.'"
          ]
        }
      ],
      "source": [
        "hyperparameter_tuning(x_train, y_train, x_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
